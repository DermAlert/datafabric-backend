# âš¡ Quick Start - MicroserviÃ§os Data Fabric

Guia rÃ¡pido para subir e testar a arquitetura de microserviÃ§os.

## ğŸš€ 1. Subir os ServiÃ§os

```bash
# Clone o repositÃ³rio (se necessÃ¡rio)
cd /home/hmsb/datafabric-backend

# Construir e subir todos os serviÃ§os
docker-compose up --build -d

# Aguardar todos os serviÃ§os estarem prontos (pode levar 2-3 minutos)
```

## âœ… 2. Verificar Status dos ServiÃ§os

```bash
# Verificar se todos os containers estÃ£o rodando
docker-compose ps

# Testar health checks
curl http://localhost:8004/                    # API Principal
curl http://localhost:8007/health              # Sync Service  
curl http://localhost:8006/health              # Dataset Service
curl http://localhost:8080/health              # Airflow
```

**Esperado:** Todos devem retornar status 200.

## âš™ï¸ 3. Configurar Airflow

```bash
# Executar script de configuraÃ§Ã£o dos POOLs
python setup_airflow_pools.py
```

**Output esperado:**
```
âœ… Airflow estÃ¡ disponÃ­vel!
ğŸ“‹ POOLs configurados: ['sync_pool', 'dataset_pool']  
ğŸ”Œ ConexÃµes configuradas: ['sync_service_conn', 'dataset_service_conn']
âœ… ConfiguraÃ§Ã£o do Airflow concluÃ­da!
```

## ğŸ”§ 4. Verificar Airflow UI

1. Acesse: http://localhost:8080
2. Login: `airflow` / `airflow`
3. Verifique se os DAGs estÃ£o disponÃ­veis:
   - `sync_data_connection`
   - `create_unified_dataset`

## ğŸ§ª 5. Testar Sync de ConexÃ£o

```bash
# Executar sync da conexÃ£o ID 1
curl -X POST http://localhost:8004/api/data-connections/1/sync
```

**Resposta esperada:**
```json
{
  "message": "Metadata synchronization for connection 'MyConnection' has been queued",
  "dag_run_id": "sync_1_1734567890",
  "dag_id": "sync_data_connection",
  "airflow_url": "http://localhost:8080/dags/sync_data_connection/grid?dag_run_id=sync_1_1734567890",
  "connection_id": 1,
  "status": "queued"
}
```

## ğŸ“Š 6. Testar CriaÃ§Ã£o de Dataset

```bash
# Criar dataset unificado
curl -X POST http://localhost:8004/api/datasets/unified \
  -H "Content-Type: application/json" \
  -d '{
    "name": "test_unified_dataset",
    "selection_mode": "tables",
    "selected_tables": [1, 2],
    "auto_include_mapped_columns": true,
    "apply_value_mappings": true,
    "storage_type": "copy_to_minio"
  }'
```

**Resposta esperada:**
```json
{
  "message": "Dataset creation for 'test_unified_dataset' has been queued",
  "dag_run_id": "dataset_test_unified_dataset_1734567890",
  "dag_id": "create_unified_dataset",
  "status": "queued",
  "estimated_processing_time": "2-10 minutes depending on data volume"
}
```

## ğŸ‘€ 7. Monitorar ExecuÃ§Ã£o

### Via Airflow UI:
1. Acesse: http://localhost:8080
2. Clique no DAG executado
3. Veja o progresso das tasks em tempo real

### Via Logs:
```bash
# Logs do sync service
docker-compose logs -f sync-service

# Logs do dataset service
docker-compose logs -f dataset-service
```

## ğŸ¯ 8. Verificar Pools

No Airflow UI:
1. Admin â†’ Pools
2. Verifique:
   - `sync_pool`: 3 slots
   - `dataset_pool`: 2 slots

## âŒ SoluÃ§Ã£o de Problemas RÃ¡pidos

### ServiÃ§o nÃ£o responde:
```bash
# Reiniciar serviÃ§o especÃ­fico
docker-compose restart sync-service
docker-compose restart dataset-service
```

### DAG nÃ£o aparece:
```bash
# Reiniciar Airflow
docker-compose restart airflow-scheduler
docker-compose restart airflow-webserver
```

### Erro de conexÃ£o com banco:
```bash
# Verificar se PostgreSQL estÃ¡ rodando
docker-compose ps postgres-backend

# Reiniciar se necessÃ¡rio
docker-compose restart postgres-backend
```

## ğŸ“ˆ Status de Sucesso

Quando tudo estiver funcionando, vocÃª verÃ¡:

1. **Containers rodando:** `docker-compose ps` mostra todos UP
2. **Health checks OK:** Todos os endpoints respondem 200
3. **DAGs visÃ­veis:** Aparecem no Airflow UI
4. **Jobs executando:** Tasks progridem no Airflow
5. **Logs limpos:** Sem erros nos logs dos serviÃ§os

## ğŸ”— URLs Importantes

- **API Principal:** http://localhost:8004
- **Sync Service:** http://localhost:8005
- **Dataset Service:** http://localhost:8006
- **Airflow UI:** http://localhost:8080
- **MinIO UI:** http://localhost:9001

## ğŸ“ PrÃ³ximos Passos

ApÃ³s o setup funcionar:
1. Consulte o `README_MICROSERVICES.md` para detalhes completos
2. Teste com dados reais
3. Configure monitoramento adicional
4. Ajuste pools conforme necessÃ¡rio

---

**ğŸ‰ ParabÃ©ns! Sua arquitetura de microserviÃ§os estÃ¡ funcionando!**
