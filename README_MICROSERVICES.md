# ğŸš€ MicroserviÃ§os Data Fabric

Este documento descreve a arquitetura de microserviÃ§os implementada para separar as funcionalidades de **Sync de ConexÃµes** e **CriaÃ§Ã£o de Datasets Unificados** do monÃ³lito principal.

## ğŸ“‹ VisÃ£o Geral

### Arquitetura Anterior (MonÃ³lito)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          FastAPI Backend           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Sync Route  â”‚ â”‚ Dataset Route â”‚  â”‚
â”‚  â”‚     +       â”‚ â”‚      +        â”‚  â”‚
â”‚  â”‚ Background  â”‚ â”‚  Heavy Proc.  â”‚  â”‚
â”‚  â”‚   Tasks     â”‚ â”‚   (Gargalo)   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Nova Arquitetura (MicroserviÃ§os + Airflow)
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   API Gateway   â”‚    â”‚     Airflow     â”‚
â”‚   (Main API)    â”‚â”€â”€â”€â”€â”‚   Orchestrator  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚                   â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
            â”‚ Sync Service â”‚    â”‚Dataset Serviceâ”‚
            â”‚  (Port 8005) â”‚    â”‚  (Port 8006) â”‚
            â”‚              â”‚    â”‚              â”‚
            â”‚ sync_pool    â”‚    â”‚ dataset_pool â”‚
            â”‚ (3 workers)  â”‚    â”‚ (2 workers)  â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ—ï¸ Componentes

### 1. **Sync Service** (Port 8007)
**Responsabilidade:** Processar sincronizaÃ§Ã£o de metadados de conexÃµes de dados.

**Endpoints:**
- `GET /health` - Health check
- `POST /process-sync` - Processar job de sync (chamado pelo Airflow)
- `GET /status/{job_id}` - Status do job

**Pool Airflow:** `sync_pool` (3 workers simultÃ¢neos)

### 2. **Dataset Service** (Port 8006)
**Responsabilidade:** Criar datasets unificados com processamento pesado.

**Endpoints:**
- `GET /health` - Health check
- `POST /process-dataset-creation` - Processar criaÃ§Ã£o de dataset (chamado pelo Airflow)
- `POST /preview-dataset-creation` - Preview do dataset
- `GET /status/{job_id}` - Status do job

**Pool Airflow:** `dataset_pool` (2 workers simultÃ¢neos)

### 3. **API Principal** (Port 8004)
**Responsabilidade:** Receber requests e disparar DAGs do Airflow.

**MudanÃ§as nos Endpoints:**
- `POST /data-connections/{id}/sync` â†’ Dispara DAG `sync_data_connection`
- `POST /datasets/unified` â†’ Dispara DAG `create_unified_dataset`

### 4. **Airflow DAGs**
**OrquestraÃ§Ã£o:** Gerencia filas e execuÃ§Ã£o dos microserviÃ§os.

**DAGs:**
- `sync_data_connection` - Processa sync de conexÃµes
- `create_unified_dataset` - Processa criaÃ§Ã£o de datasets

## ğŸš€ Como Usar

### 1. **Subir os ServiÃ§os**

```bash
# Construir e subir todos os serviÃ§os
docker-compose up --build

# Aguardar todos os serviÃ§os estarem prontos
# Airflow: http://localhost:8080
# API Principal: http://localhost:8004
# Sync Service: http://localhost:8005
# Dataset Service: http://localhost:8006
```

### 2. **Configurar Airflow**

```bash
# Executar script de configuraÃ§Ã£o dos POOLs
python setup_airflow_pools.py
```

Este script configura:
- **Pools:** `sync_pool` (3 slots) e `dataset_pool` (2 slots)
- **ConexÃµes HTTP:** Para comunicaÃ§Ã£o com os microserviÃ§os

### 3. **Testar Health Checks**

```bash
# API Principal
curl http://localhost:8004/

# Sync Service
curl http://localhost:8005/health

# Dataset Service  
curl http://localhost:8006/health

# Airflow
curl http://localhost:8080/health
```

### 4. **Executar Sync de ConexÃ£o**

```bash
curl -X POST http://localhost:8004/api/data-connections/1/sync
```

**Resposta:**
```json
{
  "message": "Metadata synchronization for connection 'MyConnection' has been queued",
  "dag_run_id": "sync_1_1734567890",
  "dag_id": "sync_data_connection",
  "airflow_url": "http://localhost:8080/dags/sync_data_connection/grid?dag_run_id=sync_1_1734567890",
  "connection_id": 1,
  "status": "queued"
}
```

### 5. **Executar CriaÃ§Ã£o de Dataset**

```bash
curl -X POST http://localhost:8004/api/datasets/unified \
  -H "Content-Type: application/json" \
  -d '{
    "name": "unified_dataset_test",
    "selection_mode": "tables",
    "selected_tables": [1, 2, 3],
    "auto_include_mapped_columns": true,
    "apply_value_mappings": true,
    "storage_type": "copy_to_minio"
  }'
```

**Resposta:**
```json
{
  "message": "Dataset creation for 'unified_dataset_test' has been queued",
  "dag_run_id": "dataset_unified_dataset_test_1734567890",
  "dag_id": "create_unified_dataset",
  "airflow_url": "http://localhost:8080/dags/create_unified_dataset/grid?dag_run_id=dataset_unified_dataset_test_1734567890",
  "dataset_name": "unified_dataset_test",
  "selection_mode": "tables",
  "status": "queued",
  "estimated_processing_time": "2-10 minutes depending on data volume"
}
```

## ğŸ“Š Monitoramento

### 1. **Airflow UI**
- **URL:** http://localhost:8080
- **Login:** airflow / airflow
- **Ver:** DAGs, execuÃ§Ãµes, logs, POOLs

### 2. **Logs dos MicroserviÃ§os**

```bash
# Sync Service logs
docker-compose logs -f sync-service

# Dataset Service logs
docker-compose logs -f dataset-service
```

### 3. **Status via API**

```bash
# Status de job de sync
curl http://localhost:8005/status/sync_1_1734567890

# Status de job de dataset
curl http://localhost:8006/status/dataset_test_1734567890
```

## âš™ï¸ ConfiguraÃ§Ã£o de ConcorrÃªncia

### POOLs do Airflow

**Sync Pool:**
- **Nome:** `sync_pool`
- **Slots:** 3
- **Uso:** Jobs de sincronizaÃ§Ã£o de metadados
- **Tempo tÃ­pico:** 1-5 minutos

**Dataset Pool:**
- **Nome:** `dataset_pool`
- **Slots:** 2  
- **Uso:** CriaÃ§Ã£o de datasets (mais pesado)
- **Tempo tÃ­pico:** 2-10 minutos

### Ajustar ConcorrÃªncia

Para alterar o nÃºmero de workers simultÃ¢neos:

1. **Via Airflow UI:**
   - Admin â†’ Pools
   - Editar `sync_pool` ou `dataset_pool`
   - Alterar nÃºmero de slots

2. **Via Script:**
   - Editar `setup_airflow_pools.py`
   - Alterar valores em `POOLS_CONFIG`
   - Executar novamente

## ğŸ”§ Desenvolvimento

### Estrutura dos MicroserviÃ§os

```
sync-service/
â”œâ”€â”€ main.py          # FastAPI app
â”œâ”€â”€ Dockerfile       # Container config
â””â”€â”€ requirements     # Dependencies (shared from main project)

dataset-service/
â”œâ”€â”€ main.py          # FastAPI app  
â”œâ”€â”€ Dockerfile       # Container config
â””â”€â”€ requirements     # Dependencies (shared from main project)

dags/
â”œâ”€â”€ sync_connection_dag.py     # DAG para sync
â””â”€â”€ create_dataset_dag.py      # DAG para datasets
```

### Adicionar Novo MicroserviÃ§o

1. **Criar diretÃ³rio** `new-service/`
2. **Implementar** `main.py` com FastAPI
3. **Criar** `Dockerfile`
4. **Adicionar** ao `docker-compose.yml`
5. **Criar** DAG no Airflow
6. **Configurar** POOL se necessÃ¡rio

### Debug

**Logs detalhados:**
```bash
# Todos os serviÃ§os
docker-compose logs -f

# ServiÃ§o especÃ­fico
docker-compose logs -f sync-service
```

**Acessar container:**
```bash
# Sync service
docker-compose exec sync-service bash

# Dataset service
docker-compose exec dataset-service bash
```

## ğŸš¨ SoluÃ§Ã£o de Problemas

### Problema: DAG nÃ£o encontrado
**SoluÃ§Ã£o:** Verificar se os DAGs estÃ£o na pasta `/dags` e se o Airflow reiniciou.

### Problema: Pool nÃ£o existe
**SoluÃ§Ã£o:** Executar `python setup_airflow_pools.py`

### Problema: MicroserviÃ§o nÃ£o responde
**SoluÃ§Ã£o:** 
1. Verificar health check: `curl http://localhost:8005/health`
2. Ver logs: `docker-compose logs sync-service`
3. Reiniciar: `docker-compose restart sync-service`

### Problema: Job fica em pending
**SoluÃ§Ã£o:**
1. Verificar Pool slots disponÃ­veis no Airflow UI
2. Verificar se workers estÃ£o rodando
3. Ver logs do DAG para erros

### Problema: Erro de conexÃ£o com banco
**SoluÃ§Ã£o:**
1. Verificar se PostgreSQL estÃ¡ rodando
2. Verificar variÃ¡veis de ambiente (`.env`)
3. Aguardar serviÃ§os dependencies estarem prontos

## ğŸ“ˆ BenefÃ­cios da Arquitetura

### âœ… **Vantagens**

1. **Isolamento:** Falhas em um serviÃ§o nÃ£o afetam o outro
2. **Escalabilidade:** Cada serviÃ§o pode ser escalado independentemente
3. **Controle de ConcorrÃªncia:** POOLs do Airflow evitam sobrecarga
4. **Monitoramento:** Visibilidade granular via Airflow UI
5. **Manutenibilidade:** CÃ³digo separado por responsabilidade
6. **RecuperaÃ§Ã£o:** Jobs podem ser reexecutados individualmente

### ğŸ“Š **MÃ©tricas de Performance**

**Antes (MonÃ³lito):**
- Sync + Dataset simultÃ¢neos = Gargalo
- Sem controle de concorrÃªncia
- Falha em um afeta tudo

**Depois (MicroserviÃ§os):**
- Sync: 3 jobs simultÃ¢neos
- Dataset: 2 jobs simultÃ¢neos  
- Isolamento de falhas
- Fila organizada pelo Airflow

## ğŸ”® PrÃ³ximos Passos

1. **MÃ©tricas:** Implementar Prometheus + Grafana
2. **Alertas:** NotificaÃ§Ãµes de falha via Slack/Email
3. **Auto-scaling:** Baseado em carga da fila
4. **Circuit Breaker:** Para falhas de dependÃªncias
5. **Retry Policy:** ConfiguraÃ§Ã£o avanÃ§ada de reexecuÃ§Ã£o
6. **API Gateway:** Rate limiting e autenticaÃ§Ã£o centralizada

---

## ğŸ“ Suporte

Para dÃºvidas ou problemas:
1. Verificar logs dos serviÃ§os
2. Consultar Airflow UI
3. Verificar health checks
4. Revisar esta documentaÃ§Ã£o
